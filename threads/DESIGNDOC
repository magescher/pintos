			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Abigail Johnson <abigailjohnson@utexas.edu>
Anthony Weems   <amlweems@gmail.com>
Mitch Hinrichs  <mitch.hinrichs@utexas.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

When grading, please checkout the ‘threads’ branch. We created a separate
branch from the initial commit to avoid dependency issues.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread {
     ...
+    int64_t wakeup;                     /* When to wake a thread. */
     ...
}

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

We begin by disabling interrupts and calculating the time to wake up the thread
based on timer_ticks().  Next, we add the thread to the waiting list, sorted by
its wake-up time.  Finally, we block the thread. 

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?


We sorted the list by so that minimal time is spent iterating the list.


---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?


We disable interrupts.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

They don’t because we disable interrupts in the critical section.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

It was easy, intuitive, and efficient; this makes it a superior option to other
designs.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


struct thread {
     ... 
+    struct list donor_list;             /* Used to track threads for donation. */
+    struct list_elem donor_elem;        /* List elem for donor_list. */
+    struct lock *lock;                  /* If a thread is waiting on a lock, this is set. */
+    int base_prio;                      /* The base priority of a thread. */
     ... 
}

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

Threads: H, M, L
Locks: L1, L2

   L1    L2
H ---> M ---> L

M has donor_list: H
L has donor_list: H, M

H->lock: L1
M->lock: L2
L->lock: NULL

M has priority max(H, M) = H
L has priority max(L, M) = M

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
We maintain a list of threads sorted by priority.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

If a thread is currently holding the lock, we add the current thread to the
holder’s donor list.  Then, inside sema_down we modify the lock holder’s
priority if it is lower than that of the current thread’s.  We then perform
this operation on the lock holder recursively until we reach a depth of 8
donations. 

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

We remove all threads from the current thread’s donor list that are waiting on
the released lock.  Next, we reset the current thread’s priority using the
highest element in the donor list.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

We cannot use locks because locks modify priorities by donation.  We did not
experience a race condition throughout our testing.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?


This design worked for us; other designs did not.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


Not applicable.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:


Not applicable.

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?


Not applicable.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?


Not applicable.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?


Not applicable.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?


Not applicable.
